{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab665341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b16790",
   "metadata": {},
   "source": [
    "# 1. Conceptualize the Data\n",
    "\n",
    "**Grain**  \n",
    "Each row = one streaming event (a single user–content interaction), identified by `USER_ID`, `SESSION_ID` and `CONTENT_ID`.\n",
    "\n",
    "**Key Metrics**  \n",
    "- **Binge & Retention:** binge session count, total binge minutes, `CHURN_RISK_SCORE`  \n",
    "- **Ad Performance:** `AD_IMPRESSIONS`, `AD_CLICKS`, CTR (`AD_CLICKS/AD_IMPRESSIONS`), `ECPM_USD`, ecommerce conversion rate  \n",
    "- **Inventory & Revenue:** `FILL_RATE`, average `ECPM_USD`, `REVENUE_USD`, `MARGIN_USD`\n",
    "\n",
    "**Key Dimensions**  \n",
    "- **User & Segment:** `AGE_GROUP`, `SUBSCRIPTION_TYPE`  \n",
    "- **Time:** `VIEW_DATE` (date), session window (e.g. last 30 days)  \n",
    "- **Geography & Platform:** `COUNTRY_CODE`, `DEVICE_TYPE`, `PLATFORM`  \n",
    "- **Content:** `CONTENT_TYPE`, `GENRE`, and combinations like `PLATFORM`×`GENRE`\n",
    "\n",
    "**Example Record Story**  \n",
    "> On **2024-10-12** at **19:30**, **User U01234** (Age 25–34, Premium) watched **Content C04567** (“Episode Title 123”, Drama) in a binge session:  \n",
    "> - **Watch Duration:** 1,200 s (75% complete)  \n",
    "> - **Binge Sessions (30 d):** 4 sessions; **Binge Minutes:** 80 min  \n",
    "> - **Ad Performance:** 4 impressions, 1 click → **CTR:** 25%; **eCPM:** \\$8.50; **Ecom Conversion:** Y  \n",
    "> - **Inventory Metrics:** **Fill Rate:** 85%; **Revenue:** \\$3.50; **Margin:** \\$2.10  \n",
    "> - **Churn Risk Score:** 0.10  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d58ce",
   "metadata": {},
   "source": [
    "# 2. Locate Solvable Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5d4ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load raw data\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/content_events_50k_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32db29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define your issues‐logging class\n",
    "\n",
    "class IssuesLogger:\n",
    "    \"\"\"\n",
    "    IssuesLogger performs data validation on a DataFrame,\n",
    "    logging issues related to single-column and cross-field inconsistencies.\n",
    "\n",
    "    It supports:\n",
    "    - Null/missing value checks\n",
    "    - Data type, format, range, and categorical validation\n",
    "    - Duplicate detection\n",
    "    - Cross-field logical checks (e.g., date ordering, session/user ID consistency)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize with the DataFrame to check.\n",
    "\n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The data to validate.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.issues = []\n",
    "\n",
    "        # Define your expectations here or pass them in later if preferred\n",
    "        self.EXPECTED = {\n",
    "            \"AGE_GROUP\":        [\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"],\n",
    "            \"GENDER\":           [\"Male\",\"Female\",\"Other\",\"Prefer not to say\"],\n",
    "            \"COUNTRY_CODE\":     None,  # checked by regex\n",
    "            \"IS_RETURNING_USER\": [\"Y\",\"N\"],\n",
    "            \"CONTENT_TYPE\":     df[\"CONTENT_TYPE\"].dropna().unique().tolist(),\n",
    "            \"IS_BINGE_SESSION\": [\"Y\",\"N\"],\n",
    "            \"VIEWING_MODE\":     df[\"VIEWING_MODE\"].dropna().unique().tolist(),\n",
    "            \"SUBSCRIPTION_TYPE\":df[\"SUBSCRIPTION_TYPE\"].dropna().unique().tolist(),\n",
    "            \"AD_EXPOSURE\":      [\"Y\",\"N\"],\n",
    "            \"ECOMMERCE_CONVERSION\":[\"Y\",\"N\"],\n",
    "            \"IS_1ST_PARTY_DATA\": [\"Y\",\"N\"],\n",
    "            \"EXIT_REASON\":      df[\"EXIT_REASON\"].dropna().unique().tolist(),\n",
    "            \"DATA_SOURCE\":      df[\"DATA_SOURCE\"].dropna().unique().tolist(),\n",
    "        }\n",
    "\n",
    "        self.REGEX = {\n",
    "            \"USER_ID\":    r\"^U\\d+$\",\n",
    "            \"SESSION_ID\": r\"^U\\d+_S\\d+$\",\n",
    "            \"CONTENT_ID\": r\"^C\\d+$\",\n",
    "            \"COUNTRY_CODE\": r\"^[A-Z]{2}$\",\n",
    "        }\n",
    "\n",
    "        self.RANGES = {\n",
    "            \"CHURN_RISK_SCORE\":   (0.0, 1.0),\n",
    "            \"PERCENT_COMPLETED\":  (0.0, 100.0),\n",
    "            \"DURATION_SEC\":       (0, None),\n",
    "            \"WATCH_DURATION_SEC\": (0, None),\n",
    "            \"FILL_RATE\":          (0.0, 100.0),\n",
    "            # add other numeric ranges as needed\n",
    "        }\n",
    "\n",
    "    def log(self, idx, col, issue, value, solvable=\"TBC\", resolution=None):\n",
    "        \"\"\"\n",
    "        Append an issue record to the issues list.\n",
    "\n",
    "        Parameters:\n",
    "            idx (int): Row index in original DataFrame.\n",
    "            col (str or None): Column name related to the issue.\n",
    "            issue (str): Description of the issue.\n",
    "            value: Offending value(s).\n",
    "            solvable (str): Whether issue is solvable (\"Yes\", \"No\", \"TBC\").\n",
    "            resolution (str or None): Suggested resolution action.\n",
    "        \"\"\"\n",
    "        self.issues.append({\n",
    "            \"row\":       idx,\n",
    "            \"column\":    col,\n",
    "            \"issue\":     issue,\n",
    "            \"value\":     value,\n",
    "            \"solvable?\": solvable,\n",
    "            \"resolution\": resolution\n",
    "        })\n",
    "\n",
    "    def check_nulls(self):\n",
    "        \"\"\"Check for null or missing values across all columns.\"\"\"\n",
    "        for col in self.df:\n",
    "            null_idx = self.df.index[self.df[col].isna()]\n",
    "            for idx in null_idx:\n",
    "                self.log(idx, col, \"Null/Missing\", None, \"TBC\",\n",
    "                         \"Decide on drop or impute\")\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        \"\"\"Identify fully duplicated rows.\"\"\"\n",
    "        dup_idx = self.df[self.df.duplicated(keep=False)].index\n",
    "        for idx in dup_idx:\n",
    "            self.log(idx, None, \"Duplicate row\", None, \"Yes\",\n",
    "                     \"drop_duplicates() later\")\n",
    "\n",
    "    def check_categoricals(self, expected_dict=None):\n",
    "        \"\"\"\n",
    "        Validate categorical columns against expected categories.\n",
    "\n",
    "        Parameters:\n",
    "            expected_dict (dict): Mapping of column to list of allowed categories.\n",
    "        \"\"\"\n",
    "        if expected_dict is None:\n",
    "            expected_dict = self.EXPECTED\n",
    "\n",
    "        for col, allowed in expected_dict.items():\n",
    "            if allowed is None:\n",
    "                continue\n",
    "            for idx, val in self.df[col].dropna().items():\n",
    "                if val not in allowed:\n",
    "                    sol = \"Yes\" if str(val).lower() in map(str.lower, allowed) else \"TBC\"\n",
    "                    res = f\"Map to one of {allowed}\"\n",
    "                    self.log(idx, col, \"Unexpected category\", val, sol, res)\n",
    "\n",
    "    def check_regex(self, regex_dict=None):\n",
    "        \"\"\"\n",
    "        Validate string formats using regex patterns.\n",
    "\n",
    "        Parameters:\n",
    "            regex_dict (dict): Mapping of column to regex pattern.\n",
    "        \"\"\"\n",
    "        if regex_dict is None:\n",
    "            regex_dict = self.REGEX\n",
    "\n",
    "        for col, pat in regex_dict.items():\n",
    "            for idx, val in self.df[col].dropna().items():\n",
    "                if not re.match(pat, str(val)):\n",
    "                    self.log(idx, col, f\"Bad format (≠ {pat})\", val, \"TBC\",\n",
    "                             f\"Enforce regex {pat}\")\n",
    "\n",
    "    def check_ranges(self, ranges_dict=None):\n",
    "        \"\"\"\n",
    "        Check numeric columns are within specified ranges.\n",
    "\n",
    "        Parameters:\n",
    "            ranges_dict (dict): Mapping of column to (min, max) tuple.\n",
    "        \"\"\"\n",
    "        if ranges_dict is None:\n",
    "            ranges_dict = self.RANGES\n",
    "\n",
    "        for col, (lo, hi) in ranges_dict.items():\n",
    "            ser = pd.to_numeric(self.df[col], errors=\"coerce\")\n",
    "            mask = ser.notna() & ((lo is not None and ser < lo) | (hi is not None and ser > hi))\n",
    "            for idx in ser[mask].index:\n",
    "                self.log(idx, col, f\"Out of bounds [{lo},{hi}]\", self.df.at[idx,col],\n",
    "                         \"TBC\", f\"Clamp or investigate\")\n",
    "\n",
    "    def check_date_formats(self, col, fmt=\"%Y-%m-%d\"):\n",
    "        \"\"\"\n",
    "        Validate that date columns conform to a specified format.\n",
    "\n",
    "        Parameters:\n",
    "            col (str): Column name.\n",
    "            fmt (str): Expected date format string.\n",
    "        \"\"\"\n",
    "        for idx, val in self.df[col].dropna().items():\n",
    "            try:\n",
    "                datetime.strptime(str(val), fmt)\n",
    "            except Exception:\n",
    "                self.log(idx, col, f\"Bad date format (not {fmt})\", val, \"Yes\",\n",
    "                         f\"Reformat to {fmt}\")\n",
    "\n",
    "    def check_user_id(self):\n",
    "        \"\"\"\n",
    "        Validate USER_ID values, flag missing or BAD_ID patterns.\n",
    "        Attempt to infer USER_ID from SESSION_ID prefix when possible.\n",
    "        \"\"\"\n",
    "        for idx, val in self.df[\"USER_ID\"].items():\n",
    "            val_str = str(val) if pd.notna(val) else \"\"\n",
    "            if pd.isna(val) or val_str.startswith(\"BAD_ID_\"):\n",
    "                session_id = self.df.at[idx, \"SESSION_ID\"]\n",
    "                if pd.notna(session_id) and \"_\" in session_id:\n",
    "                    possible_user = session_id.split(\"_\")[0]\n",
    "                    self.log(\n",
    "                        idx,\n",
    "                        \"USER_ID\",\n",
    "                        \"Missing or bad USER_ID, possible from SESSION_ID\",\n",
    "                        val,\n",
    "                        \"TBC\",\n",
    "                        f\"Check with stakeholder, then use USER_ID from SESSION_ID\"\n",
    "                    )\n",
    "                else:\n",
    "                    self.log(\n",
    "                        idx,\n",
    "                        \"USER_ID\",\n",
    "                        \"Missing or bad USER_ID\",\n",
    "                        val,\n",
    "                        \"TBC\",\n",
    "                        \"No SESSION_ID to infer USER_ID from\"\n",
    "                    )\n",
    "\n",
    "    def check_cross_field(self):\n",
    "        \"\"\"\n",
    "        Perform cross-field validations including logical date orders,\n",
    "        session and user ID consistency, ads rules, and duration checks.\n",
    "        \"\"\"\n",
    "        # Convert datetime columns upfront for efficiency\n",
    "        acd = pd.to_datetime(self.df[\"ACCOUNT_CREATION_DATE\"], errors=\"coerce\")\n",
    "        rel = pd.to_datetime(self.df[\"RELEASE_DATE\"], errors=\"coerce\")\n",
    "        start = pd.to_datetime(self.df[\"START_TIME\"], errors=\"coerce\")\n",
    "        end = pd.to_datetime(self.df[\"END_TIME\"], errors=\"coerce\")\n",
    "        view_date = pd.to_datetime(self.df[\"VIEW_DATE\"], errors=\"coerce\") if \"VIEW_DATE\" in self.df else None\n",
    "\n",
    "        # 1) START_TIME ≤ END_TIME\n",
    "        mask_start_after_end = start > end\n",
    "        for idx in self.df[mask_start_after_end].index:\n",
    "            self.log(idx, \"START_TIME/END_TIME\", \"start > end\", \n",
    "                     (self.df.at[idx,\"START_TIME\"], self.df.at[idx,\"END_TIME\"]),\n",
    "                     \"TBC\", \"Swap or investigate timestamps\")\n",
    "\n",
    "        # 2) RELEASE_DATE ≤ START_TIME\n",
    "        mask_release_after_start = rel > start\n",
    "        for idx in self.df[mask_release_after_start].index:\n",
    "            self.log(idx, \"RELEASE_DATE/START_TIME\", \"release after start\",\n",
    "                     (self.df.at[idx,\"RELEASE_DATE\"], self.df.at[idx,\"START_TIME\"]),\n",
    "                     \"TBC\", \"Fix source or drop\")\n",
    "\n",
    "        # 3) ACCOUNT_CREATION_DATE ≤ START_TIME\n",
    "        mask_acd_after_start = acd > start\n",
    "        for idx in self.df[mask_acd_after_start].index:\n",
    "            self.log(idx, \"ACCOUNT_CREATION_DATE/START_TIME\", \"account created after start\",\n",
    "                     (self.df.at[idx,\"ACCOUNT_CREATION_DATE\"], self.df.at[idx,\"START_TIME\"]),\n",
    "                     \"TBC\", \"Check source or drop\")\n",
    "\n",
    "        # 4) START_TIME and END_TIME within VIEW_DATE (if VIEW_DATE present)\n",
    "        if view_date is not None:\n",
    "            mask_start_before_view = start.dt.date < view_date.dt.date\n",
    "            mask_end_after_view = end.dt.date > view_date.dt.date\n",
    "            for idx in self.df[mask_start_before_view | mask_end_after_view].index:\n",
    "                self.log(idx, \"START_TIME/END_TIME/VIEW_DATE\", \"session times outside VIEW_DATE\",\n",
    "                         (self.df.at[idx,\"START_TIME\"], self.df.at[idx,\"END_TIME\"], self.df.at[idx,\"VIEW_DATE\"]),\n",
    "                         \"TBC\", \"Check session and view date consistency\")\n",
    "\n",
    "        # 5) WATCH_DURATION_SEC ≈ END_TIME - START_TIME (±1 second)\n",
    "        for idx, row in self.df.iterrows():\n",
    "            try:\n",
    "                delta = (pd.to_datetime(row[\"END_TIME\"]) - pd.to_datetime(row[\"START_TIME\"])).total_seconds()\n",
    "                if pd.notna(row[\"WATCH_DURATION_SEC\"]) and abs(delta - row[\"WATCH_DURATION_SEC\"]) > 1:\n",
    "                    self.log(idx, \"WATCH_DURATION_SEC\", \"Duration mismatch\", row[\"WATCH_DURATION_SEC\"], \"TBC\",\n",
    "                             \"Recompute from timestamps\")\n",
    "            except Exception:\n",
    "                # Ignore rows with invalid timestamps here, already caught elsewhere\n",
    "                pass\n",
    "\n",
    "        # 6) Ads specific rules\n",
    "        ad_mask = self.df[\"CONTENT_TYPE\"].str.lower() == \"ad\"\n",
    "        for idx in self.df[ad_mask].index:\n",
    "            row = self.df.loc[idx]\n",
    "            # content_title must include \"Ad Creative\"\n",
    "            if \"ad creative\" not in str(row[\"CONTENT_TITLE\"]).lower():\n",
    "                self.log(idx, \"CONTENT_TITLE\", \"Ad missing 'Ad Creative'\", row[\"CONTENT_TITLE\"], \"TBC\")\n",
    "\n",
    "            # AD_EXPOSURE must be \"Y\"\n",
    "            if row[\"AD_EXPOSURE\"] != \"Y\":\n",
    "                self.log(idx, \"AD_EXPOSURE\", \"Ad must have exposure 'Y'\", row[\"AD_EXPOSURE\"], \"Yes\", \"Set to 'Y'\")\n",
    "\n",
    "            # AD_ID must be present\n",
    "            if pd.isna(row[\"AD_ID\"]):\n",
    "                self.log(idx, \"AD_ID\", \"Missing AD_ID for Ad content\", None, \"TBC\")\n",
    "\n",
    "            # RATING should be null for ads\n",
    "            if pd.notna(row[\"RATING\"]):\n",
    "                self.log(idx, \"RATING\", \"Ads should not have rating\", row[\"RATING\"], \"Yes\", \"Drop rating\")\n",
    "\n",
    "        # 7) CONTENT_TYPE and AD_EXPOSURE consistency for non-ads\n",
    "        non_ad_mask = self.df[\"CONTENT_TYPE\"].str.lower() != \"ad\"\n",
    "        for idx in self.df[non_ad_mask].index:\n",
    "            row = self.df.loc[idx]\n",
    "            if row[\"AD_EXPOSURE\"] not in [None, \"N\", \"n\", \"\"]:\n",
    "                self.log(idx, \"AD_EXPOSURE\", \"Non-ad content should not have AD_EXPOSURE 'Y'\", row[\"AD_EXPOSURE\"], \"Yes\", \"Set to 'N' or null\")\n",
    "\n",
    "            if pd.notna(row.get(\"AD_ID\", None)):\n",
    "                self.log(idx, \"AD_ID\", \"Non-ad content should not have AD_ID\", row[\"AD_ID\"], \"Yes\", \"Clear AD_ID\")\n",
    "\n",
    "        # 8) EPISODE_NUMBER numeric & positive if CONTENT_TYPE == \"show\"\n",
    "        show_mask = self.df[\"CONTENT_TYPE\"].str.lower() == \"show\"\n",
    "        for idx in self.df[show_mask].index:\n",
    "            val = self.df.at[idx, \"EPISODE_NUMBER\"] if \"EPISODE_NUMBER\" in self.df else None\n",
    "            if pd.isna(val) or not (isinstance(val, (int, float)) and val > 0):\n",
    "                self.log(idx, \"EPISODE_NUMBER\", \"Invalid episode number for show content\", val, \"TBC\", \"Ensure positive integer episode number\")\n",
    "\n",
    "        # 9) USER_ID and SESSION_ID matching\n",
    "        for idx, session_val in self.df[\"SESSION_ID\"].dropna().items():\n",
    "            if \"_\" in session_val:\n",
    "                user_part = session_val.split(\"_\")[0]\n",
    "                actual_user = self.df.at[idx, \"USER_ID\"]\n",
    "                if actual_user != user_part:\n",
    "                    self.log(idx, \"SESSION_ID/USER_ID\", \"SESSION_ID user part and USER_ID mismatch\",\n",
    "                             (actual_user, user_part), \"TBC\", \"Investigate source or align USER_ID with SESSION_ID\")\n",
    "\n",
    "    def run_all(self):\n",
    "        \"\"\"\n",
    "        Run all checks in a logical sequence.\n",
    "        \"\"\"\n",
    "        self.check_nulls()\n",
    "        self.check_duplicates()\n",
    "        self.check_categoricals()\n",
    "        self.check_regex()\n",
    "        self.check_ranges()\n",
    "        self.check_date_formats(\"ACCOUNT_CREATION_DATE\", \"%Y-%m-%d\")\n",
    "        self.check_date_formats(\"RELEASE_DATE\", \"%Y-%m-%d\")\n",
    "        if \"VIEW_DATE\" in self.df:\n",
    "            self.check_date_formats(\"VIEW_DATE\", \"%Y-%m-%d\")\n",
    "        self.check_user_id()\n",
    "        self.check_cross_field()\n",
    "\n",
    "    def issues_df(self):\n",
    "        \"\"\"\n",
    "        Aggregate issues by type and return a summary DataFrame with counts.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Summary of issues grouped by column, issue, solvable, and resolution,\n",
    "                          with row counts of affected rows.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.issues)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=[\"column\",\"issue\",\"row_count\",\"solvable?\",\"resolution\"])\n",
    "\n",
    "        summary = (\n",
    "            df\n",
    "            .groupby(\n",
    "                [\"column\",\"issue\",\"solvable?\",\"resolution\"],\n",
    "                dropna=False,\n",
    "                as_index=False\n",
    "            )\n",
    "            .agg(row_count = pd.NamedAgg(column=\"row\", aggfunc=lambda x: x.nunique()))\n",
    "        )\n",
    "        return summary[\n",
    "            [\"column\",\"issue\",\"row_count\",\"solvable?\",\"resolution\"]\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52592b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           column  \\\n",
      "8                  EPISODE_NUMBER   \n",
      "12                         RATING   \n",
      "2                     AD_EXPOSURE   \n",
      "4                           AD_ID   \n",
      "5                           AD_ID   \n",
      "7                        ECPM_USD   \n",
      "13        RELEASE_DATE/START_TIME   \n",
      "6                    COUNTRY_CODE   \n",
      "11                         RATING   \n",
      "15             SESSION_ID/USER_ID   \n",
      "3                           AD_ID   \n",
      "1                     AD_EXPOSURE   \n",
      "9                          GENDER   \n",
      "16  START_TIME/END_TIME/VIEW_DATE   \n",
      "10              IS_RETURNING_USER   \n",
      "\n",
      "                                             issue  row_count solvable?  \\\n",
      "8                                     Null/Missing      30909       TBC   \n",
      "12                                    Null/Missing      28530       TBC   \n",
      "2   Non-ad content should not have AD_EXPOSURE 'Y'      25911       Yes   \n",
      "4             Non-ad content should not have AD_ID      25911       Yes   \n",
      "5                                     Null/Missing      21259       TBC   \n",
      "7                                     Null/Missing      21259       TBC   \n",
      "13                             release after start       6643       TBC   \n",
      "6                        Bad format (≠ ^[A-Z]{2}$)       3969       TBC   \n",
      "11                      Ads should not have rating       2561       Yes   \n",
      "15       SESSION_ID user part and USER_ID mismatch       2499       TBC   \n",
      "3                     Missing AD_ID for Ad content       2462       TBC   \n",
      "1                        Ad must have exposure 'Y'       2462       Yes   \n",
      "9                              Unexpected category       2387       TBC   \n",
      "16                 session times outside VIEW_DATE       2041       TBC   \n",
      "10                             Unexpected category       2020       TBC   \n",
      "\n",
      "                                           resolution  \n",
      "8                            Decide on drop or impute  \n",
      "12                           Decide on drop or impute  \n",
      "2                                  Set to 'N' or null  \n",
      "4                                         Clear AD_ID  \n",
      "5                            Decide on drop or impute  \n",
      "7                            Decide on drop or impute  \n",
      "13                                 Fix source or drop  \n",
      "6                            Enforce regex ^[A-Z]{2}$  \n",
      "11                                        Drop rating  \n",
      "15  Investigate source or align USER_ID with SESSI...  \n",
      "3                                                 NaN  \n",
      "1                                          Set to 'Y'  \n",
      "9   Map to one of ['Male', 'Female', 'Other', 'Pre...  \n",
      "16            Check session and view date consistency  \n",
      "10                           Map to one of ['Y', 'N']  \n"
     ]
    }
   ],
   "source": [
    "# Run your audit\n",
    "audit = IssuesLogger(df)\n",
    "audit.run_all()\n",
    "issues = audit.issues_df()\n",
    "\n",
    "# Sort by most frequent issues\n",
    "issues = issues.sort_values(by=\"row_count\", ascending=False)\n",
    "\n",
    "# Preview top 15\n",
    "print(issues.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b514685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| column                        | issue                                            |   row_count | solvable?   | resolution                                                     |\n",
      "|:------------------------------|:-------------------------------------------------|------------:|:------------|:---------------------------------------------------------------|\n",
      "| EPISODE_NUMBER                | Null/Missing                                     |       30909 | TBC         | Decide on drop or impute                                       |\n",
      "| RATING                        | Null/Missing                                     |       28530 | TBC         | Decide on drop or impute                                       |\n",
      "| AD_EXPOSURE                   | Non-ad content should not have AD_EXPOSURE 'Y'   |       25911 | Yes         | Set to 'N' or null                                             |\n",
      "| AD_ID                         | Non-ad content should not have AD_ID             |       25911 | Yes         | Clear AD_ID                                                    |\n",
      "| AD_ID                         | Null/Missing                                     |       21259 | TBC         | Decide on drop or impute                                       |\n",
      "| ECPM_USD                      | Null/Missing                                     |       21259 | TBC         | Decide on drop or impute                                       |\n",
      "| RELEASE_DATE/START_TIME       | release after start                              |        6643 | TBC         | Fix source or drop                                             |\n",
      "| COUNTRY_CODE                  | Bad format (≠ ^[A-Z]{2}$)                        |        3969 | TBC         | Enforce regex ^[A-Z]{2}$                                       |\n",
      "| RATING                        | Ads should not have rating                       |        2561 | Yes         | Drop rating                                                    |\n",
      "| SESSION_ID/USER_ID            | SESSION_ID user part and USER_ID mismatch        |        2499 | TBC         | Investigate source or align USER_ID with SESSION_ID            |\n",
      "| AD_ID                         | Missing AD_ID for Ad content                     |        2462 | TBC         | nan                                                            |\n",
      "| AD_EXPOSURE                   | Ad must have exposure 'Y'                        |        2462 | Yes         | Set to 'Y'                                                     |\n",
      "| GENDER                        | Unexpected category                              |        2387 | TBC         | Map to one of ['Male', 'Female', 'Other', 'Prefer not to say'] |\n",
      "| START_TIME/END_TIME/VIEW_DATE | session times outside VIEW_DATE                  |        2041 | TBC         | Check session and view date consistency                        |\n",
      "| IS_RETURNING_USER             | Unexpected category                              |        2020 | TBC         | Map to one of ['Y', 'N']                                       |\n",
      "| SESSION_ID                    | Bad format (≠ ^U\\d+_S\\d+$)                       |        2020 | TBC         | Enforce regex ^U\\d+_S\\d+$                                      |\n",
      "| ACCOUNT_CREATION_DATE         | Bad date format (not %Y-%m-%d)                   |        2002 | Yes         | Reformat to %Y-%m-%d                                           |\n",
      "| VIEW_DATE                     | Bad date format (not %Y-%m-%d)                   |        1919 | Yes         | Reformat to %Y-%m-%d                                           |\n",
      "| VIEW_DATE                     | Null/Missing                                     |        1515 | TBC         | Decide on drop or impute                                       |\n",
      "| USER_ID                       | Bad format (≠ ^U\\d+$)                            |         505 | TBC         | Enforce regex ^U\\d+$                                           |\n",
      "| USER_ID                       | Missing or bad USER_ID, possible from SESSION_ID |         505 | TBC         | Check with stakeholder, then use USER_ID from SESSION_ID       |\n",
      "| nan                           | Duplicate row                                    |         416 | Yes         | drop_duplicates() later                                        |\n"
     ]
    }
   ],
   "source": [
    "# 4. Export your skeleton\n",
    "\n",
    "# Export full issues log to CSV\n",
    "issues.to_csv(\"../reports/01_data_issues_log.csv\", index=False)\n",
    "\n",
    "# Optionally print full table in markdown format\n",
    "print(issues.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c28d0c",
   "metadata": {},
   "source": [
    "## 5. Evaluate Unsolvable Issues\n",
    "\n",
    "Filter our issues log for the rows we marked `solvable? = N` or `solvable? = TBC` and record why we can’t fix them now, or what needs to be known before we can fix them.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
